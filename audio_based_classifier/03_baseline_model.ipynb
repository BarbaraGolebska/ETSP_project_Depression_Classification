{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81039e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 404)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>bow_egemaps_2_mean</th>\n",
       "      <th>bow_egemaps_3_mean</th>\n",
       "      <th>bow_egemaps_4_mean</th>\n",
       "      <th>bow_egemaps_5_mean</th>\n",
       "      <th>bow_egemaps_6_mean</th>\n",
       "      <th>bow_egemaps_7_mean</th>\n",
       "      <th>bow_egemaps_8_mean</th>\n",
       "      <th>bow_egemaps_9_mean</th>\n",
       "      <th>bow_egemaps_10_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>bow_mfcc_95_std</th>\n",
       "      <th>bow_mfcc_96_std</th>\n",
       "      <th>bow_mfcc_97_std</th>\n",
       "      <th>bow_mfcc_98_std</th>\n",
       "      <th>bow_mfcc_99_std</th>\n",
       "      <th>bow_mfcc_100_std</th>\n",
       "      <th>bow_mfcc_101_std</th>\n",
       "      <th>target_depr</th>\n",
       "      <th>target_ptsd</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>0.431654</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.070662</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.027842</td>\n",
       "      <td>0.008674</td>\n",
       "      <td>0.063036</td>\n",
       "      <td>0.172168</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021819</td>\n",
       "      <td>0.334112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088473</td>\n",
       "      <td>0.099869</td>\n",
       "      <td>0.317645</td>\n",
       "      <td>0.319770</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>0.688838</td>\n",
       "      <td>1.028125</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434868</td>\n",
       "      <td>0.151256</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.557120</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258597</td>\n",
       "      <td>0.297399</td>\n",
       "      <td>0.156284</td>\n",
       "      <td>0.194139</td>\n",
       "      <td>0.262813</td>\n",
       "      <td>0.503814</td>\n",
       "      <td>0.292152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304</td>\n",
       "      <td>0.594773</td>\n",
       "      <td>0.658804</td>\n",
       "      <td>0.043229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.336465</td>\n",
       "      <td>0.103073</td>\n",
       "      <td>0.010107</td>\n",
       "      <td>0.303097</td>\n",
       "      <td>0.005749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191830</td>\n",
       "      <td>0.302847</td>\n",
       "      <td>0.056409</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.180708</td>\n",
       "      <td>0.485558</td>\n",
       "      <td>0.260609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>305</td>\n",
       "      <td>0.019933</td>\n",
       "      <td>0.619588</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.023531</td>\n",
       "      <td>0.081506</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.306944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142183</td>\n",
       "      <td>0.245184</td>\n",
       "      <td>0.093239</td>\n",
       "      <td>0.226964</td>\n",
       "      <td>0.249124</td>\n",
       "      <td>0.319684</td>\n",
       "      <td>0.314181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>307</td>\n",
       "      <td>0.025780</td>\n",
       "      <td>1.408446</td>\n",
       "      <td>0.044388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349453</td>\n",
       "      <td>0.106781</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.133493</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>0.370926</td>\n",
       "      <td>0.061901</td>\n",
       "      <td>0.239680</td>\n",
       "      <td>0.292829</td>\n",
       "      <td>0.371272</td>\n",
       "      <td>0.277161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  bow_egemaps_2_mean  bow_egemaps_3_mean  bow_egemaps_4_mean  \\\n",
       "2             302            0.431654            0.008801            0.070662   \n",
       "3             303            0.688838            1.028125            0.041777   \n",
       "4             304            0.594773            0.658804            0.043229   \n",
       "5             305            0.019933            0.619588            0.009948   \n",
       "7             307            0.025780            1.408446            0.044388   \n",
       "\n",
       "   bow_egemaps_5_mean  bow_egemaps_6_mean  bow_egemaps_7_mean  \\\n",
       "2            0.003179            0.027842            0.008674   \n",
       "3            0.000000            0.434868            0.151256   \n",
       "4            0.000000            0.336465            0.103073   \n",
       "5            0.003398            0.023531            0.081506   \n",
       "7            0.000000            0.349453            0.106781   \n",
       "\n",
       "   bow_egemaps_8_mean  bow_egemaps_9_mean  bow_egemaps_10_mean  ...  \\\n",
       "2            0.063036            0.172168             0.007635  ...   \n",
       "3            0.025126            0.557120             0.003796  ...   \n",
       "4            0.010107            0.303097             0.005749  ...   \n",
       "5            0.002844            0.306944             0.000000  ...   \n",
       "7            0.002917            0.133493             0.000997  ...   \n",
       "\n",
       "   bow_mfcc_95_std  bow_mfcc_96_std  bow_mfcc_97_std  bow_mfcc_98_std  \\\n",
       "2         0.021819         0.334112         0.000000         0.088473   \n",
       "3         0.258597         0.297399         0.156284         0.194139   \n",
       "4         0.191830         0.302847         0.056409         0.100500   \n",
       "5         0.142183         0.245184         0.093239         0.226964   \n",
       "7         0.243252         0.370926         0.061901         0.239680   \n",
       "\n",
       "   bow_mfcc_99_std  bow_mfcc_100_std  bow_mfcc_101_std  target_depr  \\\n",
       "2         0.099869          0.317645          0.319770            0   \n",
       "3         0.262813          0.503814          0.292152            0   \n",
       "4         0.180708          0.485558          0.260609            0   \n",
       "5         0.249124          0.319684          0.314181            0   \n",
       "7         0.292829          0.371272          0.277161            0   \n",
       "\n",
       "   target_ptsd  split  \n",
       "2            0  train  \n",
       "3            0  train  \n",
       "4            0  train  \n",
       "5            0  train  \n",
       "7            0  train  \n",
       "\n",
       "[5 rows x 404 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(56, 404)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>bow_egemaps_2_mean</th>\n",
       "      <th>bow_egemaps_3_mean</th>\n",
       "      <th>bow_egemaps_4_mean</th>\n",
       "      <th>bow_egemaps_5_mean</th>\n",
       "      <th>bow_egemaps_6_mean</th>\n",
       "      <th>bow_egemaps_7_mean</th>\n",
       "      <th>bow_egemaps_8_mean</th>\n",
       "      <th>bow_egemaps_9_mean</th>\n",
       "      <th>bow_egemaps_10_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>bow_mfcc_95_std</th>\n",
       "      <th>bow_mfcc_96_std</th>\n",
       "      <th>bow_mfcc_97_std</th>\n",
       "      <th>bow_mfcc_98_std</th>\n",
       "      <th>bow_mfcc_99_std</th>\n",
       "      <th>bow_mfcc_100_std</th>\n",
       "      <th>bow_mfcc_101_std</th>\n",
       "      <th>target_depr</th>\n",
       "      <th>target_ptsd</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>0.339651</td>\n",
       "      <td>0.309486</td>\n",
       "      <td>0.098401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030742</td>\n",
       "      <td>0.046243</td>\n",
       "      <td>0.021366</td>\n",
       "      <td>0.221098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095374</td>\n",
       "      <td>0.329190</td>\n",
       "      <td>0.033231</td>\n",
       "      <td>0.092826</td>\n",
       "      <td>0.099744</td>\n",
       "      <td>0.422663</td>\n",
       "      <td>0.359292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>0.417114</td>\n",
       "      <td>0.508682</td>\n",
       "      <td>0.048905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178481</td>\n",
       "      <td>0.049159</td>\n",
       "      <td>0.104577</td>\n",
       "      <td>0.480422</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261580</td>\n",
       "      <td>0.305343</td>\n",
       "      <td>0.128106</td>\n",
       "      <td>0.235143</td>\n",
       "      <td>0.162115</td>\n",
       "      <td>0.467075</td>\n",
       "      <td>0.324784</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>306</td>\n",
       "      <td>0.060895</td>\n",
       "      <td>0.935911</td>\n",
       "      <td>0.026260</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.095571</td>\n",
       "      <td>0.065111</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.313527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174303</td>\n",
       "      <td>0.224284</td>\n",
       "      <td>0.081181</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.267230</td>\n",
       "      <td>0.306523</td>\n",
       "      <td>0.264263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>317</td>\n",
       "      <td>0.901303</td>\n",
       "      <td>0.100441</td>\n",
       "      <td>0.019618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.107381</td>\n",
       "      <td>0.473388</td>\n",
       "      <td>0.017541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209779</td>\n",
       "      <td>0.311567</td>\n",
       "      <td>0.078522</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.122217</td>\n",
       "      <td>0.546270</td>\n",
       "      <td>0.285626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>320</td>\n",
       "      <td>0.598851</td>\n",
       "      <td>0.527382</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291888</td>\n",
       "      <td>0.072534</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>0.328923</td>\n",
       "      <td>0.109905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231705</td>\n",
       "      <td>0.303102</td>\n",
       "      <td>0.112808</td>\n",
       "      <td>0.194180</td>\n",
       "      <td>0.228752</td>\n",
       "      <td>0.471862</td>\n",
       "      <td>0.293969</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    participant_id  bow_egemaps_2_mean  bow_egemaps_3_mean  \\\n",
       "0              300            0.339651            0.309486   \n",
       "1              301            0.417114            0.508682   \n",
       "6              306            0.060895            0.935911   \n",
       "17             317            0.901303            0.100441   \n",
       "20             320            0.598851            0.527382   \n",
       "\n",
       "    bow_egemaps_4_mean  bow_egemaps_5_mean  bow_egemaps_6_mean  \\\n",
       "0             0.098401            0.000000            0.030742   \n",
       "1             0.048905            0.000000            0.178481   \n",
       "6             0.026260            0.001445            0.095571   \n",
       "17            0.019618            0.000000            0.016212   \n",
       "20            0.010727            0.000000            0.291888   \n",
       "\n",
       "    bow_egemaps_7_mean  bow_egemaps_8_mean  bow_egemaps_9_mean  \\\n",
       "0             0.046243            0.021366            0.221098   \n",
       "1             0.049159            0.104577            0.480422   \n",
       "6             0.065111            0.004228            0.313527   \n",
       "17            0.010623            0.107381            0.473388   \n",
       "20            0.072534            0.010969            0.328923   \n",
       "\n",
       "    bow_egemaps_10_mean  ...  bow_mfcc_95_std  bow_mfcc_96_std  \\\n",
       "0              0.000000  ...         0.095374         0.329190   \n",
       "1              0.001461  ...         0.261580         0.305343   \n",
       "6              0.000000  ...         0.174303         0.224284   \n",
       "17             0.017541  ...         0.209779         0.311567   \n",
       "20             0.109905  ...         0.231705         0.303102   \n",
       "\n",
       "    bow_mfcc_97_std  bow_mfcc_98_std  bow_mfcc_99_std  bow_mfcc_100_std  \\\n",
       "0          0.033231         0.092826         0.099744          0.422663   \n",
       "1          0.128106         0.235143         0.162115          0.467075   \n",
       "6          0.081181         0.270389         0.267230          0.306523   \n",
       "17         0.078522         0.194000         0.122217          0.546270   \n",
       "20         0.112808         0.194180         0.228752          0.471862   \n",
       "\n",
       "    bow_mfcc_101_std  target_depr  target_ptsd  split  \n",
       "0           0.359292            0            0    dev  \n",
       "1           0.324784            0            0    dev  \n",
       "6           0.264263            0            0    dev  \n",
       "17          0.285626            0            1    dev  \n",
       "20          0.293969            0            1    dev  \n",
       "\n",
       "[5 rows x 404 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## get data and prepare train split and dev split\n",
    "import pandas as pd\n",
    "# get the combined dataset\n",
    "df = pd.read_csv(\"../data/processed/BoW_aggregated_features.csv\")\n",
    "\n",
    "# get only train part of the dataset\n",
    "df_train = df[df[\"split\"] == \"train\"]\n",
    "\n",
    "# get only dev part of the dataset\n",
    "df_dev = df[df[\"split\"] == \"dev\"]\n",
    "\n",
    "# get the necessary columns out of df_train\n",
    "X = df_train.drop(columns=[\"participant_id\", \"target_depr\", \"target_ptsd\", \"split\"])\n",
    "y_depr = df_train[\"target_depr\"]\n",
    "\n",
    "print(df_train.shape)\n",
    "display(df_train.head())\n",
    "print(X.index.equals(y_depr.index))\n",
    "\n",
    "# get the necessary columns out of df_dev\n",
    "X_dev = df_dev.drop(columns=[\"participant_id\", \"target_depr\", \"target_ptsd\", \"split\"])\n",
    "y_depr_dev = df_dev[\"target_depr\"]\n",
    "\n",
    "print(df_dev.shape)\n",
    "display(df_dev.head())\n",
    "print(X_dev.index.equals(y_depr_dev.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21e8375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# =========================\n",
    "# REPRODUCIBILITY SETUP\n",
    "# =========================\n",
    "def set_seed(seed=1):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22c3d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def init_weights(model):\n",
    "    \"\"\"\n",
    "    Initialize weights of linear layers using Xavier uniform initialization.\n",
    "    Biases are initialized to zero.\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f4021a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(final_model, optimizer, scheduler, criterion, X_tensor, y_tensor):\n",
    "    torch.manual_seed(1)  # Ensure reproducibility\n",
    "    final_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = final_model(X_tensor).squeeze()\n",
    "    loss = criterion(output, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "153aa1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid, StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "\n",
    "# =======================\n",
    "# HELPER FUNCTIONS\n",
    "# =======================\n",
    "def create_model(input_dim, device):\n",
    "    torch.manual_seed(1)  # Ensure reproducibility\n",
    "    return nn.Linear(input_dim, 1).to(device)\n",
    "\n",
    "def create_optimizer(model, lr, optimizer_type):\n",
    "    if optimizer_type == \"Adam\":\n",
    "        return torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        return torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "def compute_best_f2(y_true, y_proba):\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_proba)\n",
    "    f2_scores = (1 + 2**2) * prec * rec / ((2**2 * prec) + rec + 1e-12)\n",
    "    best_idx = np.argmax(f2_scores[:-1])\n",
    "    return f2_scores[best_idx], thr[best_idx]\n",
    "\n",
    "# =======================\n",
    "# GRID SEARCH WITH K-FOLD\n",
    "# =======================\n",
    "\n",
    "def grid_search(device, X_tensor, y_tensor, param_grid, kf):\n",
    "    best_f2 = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_threshold = 0\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        print(f\"\\nTesting parameters: {params}\")\n",
    "        fold_f2_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_tensor.cpu(), y_tensor.cpu())):\n",
    "            X_train, y_train = X_tensor[train_idx], y_tensor[train_idx]\n",
    "            X_val, y_val = X_tensor[val_idx], y_tensor[val_idx]\n",
    "\n",
    "            model = create_model(X_train.shape[1], device)\n",
    "            torch.manual_seed(1)  # Ensure reproducibility for each fold\n",
    "            init_weights(model)\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "            optimizer = create_optimizer(model, params[\"lr\"], params[\"optimizer_type\"])\n",
    "            torch.manual_seed(1)  # Ensure reproducibility\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=0.5, patience=5\n",
    "            )\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in range(params[\"epochs\"]):\n",
    "                train_model(model, optimizer, scheduler, criterion, X_train, y_train)\n",
    "\n",
    "            # Evaluation\n",
    "            model.eval()\n",
    "            with torch.inference_mode():\n",
    "                y_proba = torch.sigmoid(model(X_val)).cpu().numpy().flatten()\n",
    "                y_val_np = y_val.cpu().numpy()\n",
    "            \n",
    "            fold_f2, threshold = compute_best_f2(y_val_np, y_proba)\n",
    "            fold_f2_scores.append(fold_f2)\n",
    "\n",
    "        avg_f2 = np.mean(fold_f2_scores)\n",
    "        print(f\"Average F2 across folds: {avg_f2:.4f}\")\n",
    "\n",
    "        if avg_f2 > best_f2:\n",
    "            best_f2 = avg_f2\n",
    "            best_params = params\n",
    "            best_model = model  # last fold model; retrain on full set if needed\n",
    "            best_threshold = threshold\n",
    "            print(f\"→ New best F2={best_f2:.4f} at threshold={best_threshold:.3f}\")\n",
    "\n",
    "    return best_model, best_params, best_f2, best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36b98c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing parameters: {'epochs': 10, 'lr': 0.01, 'optimizer_type': 'Adam'}\n",
      "Average F2 across folds: 0.6929\n",
      "→ New best F2=0.6929 at threshold=0.206\n",
      "\n",
      "Testing parameters: {'epochs': 10, 'lr': 0.01, 'optimizer_type': 'SGD'}\n",
      "Average F2 across folds: 0.6340\n",
      "\n",
      "Testing parameters: {'epochs': 10, 'lr': 0.001, 'optimizer_type': 'Adam'}\n",
      "Average F2 across folds: 0.6442\n",
      "\n",
      "Testing parameters: {'epochs': 10, 'lr': 0.001, 'optimizer_type': 'SGD'}\n",
      "Average F2 across folds: 0.6323\n",
      "\n",
      "Testing parameters: {'epochs': 20, 'lr': 0.01, 'optimizer_type': 'Adam'}\n",
      "Average F2 across folds: 0.6926\n",
      "\n",
      "Testing parameters: {'epochs': 20, 'lr': 0.01, 'optimizer_type': 'SGD'}\n",
      "Average F2 across folds: 0.6418\n",
      "\n",
      "Testing parameters: {'epochs': 20, 'lr': 0.001, 'optimizer_type': 'Adam'}\n",
      "Average F2 across folds: 0.6602\n",
      "\n",
      "Testing parameters: {'epochs': 20, 'lr': 0.001, 'optimizer_type': 'SGD'}\n",
      "Average F2 across folds: 0.6367\n",
      "\n",
      "Testing parameters: {'epochs': 30, 'lr': 0.01, 'optimizer_type': 'Adam'}\n",
      "Average F2 across folds: 0.7042\n",
      "→ New best F2=0.7042 at threshold=0.239\n",
      "\n",
      "Testing parameters: {'epochs': 30, 'lr': 0.01, 'optimizer_type': 'SGD'}\n",
      "Average F2 across folds: 0.6501\n",
      "\n",
      "Testing parameters: {'epochs': 30, 'lr': 0.001, 'optimizer_type': 'Adam'}\n",
      "Average F2 across folds: 0.6910\n",
      "\n",
      "Testing parameters: {'epochs': 30, 'lr': 0.001, 'optimizer_type': 'SGD'}\n",
      "Average F2 across folds: 0.6367\n",
      "\n",
      "Testing parameters: {'epochs': 40, 'lr': 0.01, 'optimizer_type': 'Adam'}\n",
      "Average F2 across folds: 0.7052\n",
      "→ New best F2=0.7052 at threshold=0.196\n",
      "\n",
      "Testing parameters: {'epochs': 40, 'lr': 0.01, 'optimizer_type': 'SGD'}\n",
      "Average F2 across folds: 0.6831\n",
      "\n",
      "Testing parameters: {'epochs': 40, 'lr': 0.001, 'optimizer_type': 'Adam'}\n",
      "Average F2 across folds: 0.6985\n",
      "\n",
      "Testing parameters: {'epochs': 40, 'lr': 0.001, 'optimizer_type': 'SGD'}\n",
      "Average F2 across folds: 0.6319\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# DEVICE & TENSOR SETUP\n",
    "# =======================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32).to(device)\n",
    "y_tensor = torch.tensor(y_depr.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# =======================\n",
    "# PARAM GRID & K-FOLD\n",
    "# =======================\n",
    "param_grid = {\n",
    "    \"lr\": [0.01, 0.001],\n",
    "    \"optimizer_type\": [\"Adam\", \"SGD\"],\n",
    "    \"epochs\": [10, 20, 30, 40]\n",
    "}\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "best_model, best_params, best_f2, best_threshold = grid_search(device, X_tensor, y_tensor, param_grid, kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03d5a42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model F2 on dev set: 0.6250 at threshold=0.245 (P=0.312, R=0.833)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ninas\\anaconda3\\envs\\etasp_env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# TRAIN FINAL MODEL ON FULL TRAINING SET\n",
    "# =======================\n",
    "torch.manual_seed(1)  # Ensure reproducibility\n",
    "final_model = nn.Linear(X_tensor.shape[1], 1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer\n",
    "if best_params[\"optimizer_type\"] == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(final_model.parameters(), lr=best_params[\"lr\"])\n",
    "else:\n",
    "    optimizer = torch.optim.SGD(final_model.parameters(), lr=best_params[\"lr\"], momentum=0.9)\n",
    "\n",
    "torch.manual_seed(1)  # Ensure reproducibility\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=5, verbose=False\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(best_params[\"epochs\"]):\n",
    "    train_model(final_model, optimizer, scheduler, criterion, X_tensor, y_tensor)\n",
    "\n",
    "# =======================\n",
    "# EVALUATE ON DEV SET\n",
    "# =======================\n",
    "X_dev_tensor = torch.tensor(X_dev.values, dtype=torch.float32).to(device)\n",
    "y_dev_tensor = torch.tensor(y_depr_dev.values, dtype=torch.float32).to(device)\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_dev_proba = torch.sigmoid(final_model(X_dev_tensor)).cpu().numpy().flatten()\n",
    "    y_dev_np = y_dev_tensor.cpu().numpy()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "prec, rec, thr = precision_recall_curve(y_dev_np, y_dev_proba)\n",
    "f2_scores = (1 + 2**2) * prec * rec / ((2**2 * prec) + rec + 1e-12)\n",
    "best_idx = np.argmax(f2_scores[:-1])\n",
    "best_threshold = thr[best_idx]\n",
    "best_f2_dev = f2_scores[best_idx]\n",
    "\n",
    "print(f\"Final model F2 on dev set: {best_f2_dev:.4f} at threshold={best_threshold:.3f} \"\n",
    "      f\"(P={prec[best_idx]:.3f}, R={rec[best_idx]:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f828da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1d0ec5a4cd0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Apply the threshold to get binary predictions\n",
    "y_dev_pred = (y_dev_proba >= best_threshold).astype(int)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_dev_np, y_dev_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap=\"Blues\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc349dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etasp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
